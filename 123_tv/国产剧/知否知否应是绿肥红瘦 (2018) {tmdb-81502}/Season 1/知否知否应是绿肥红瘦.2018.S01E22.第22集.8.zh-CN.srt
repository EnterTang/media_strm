1
00:00:15,289 --> 00:00:16,500
A partial shutdown in the U.S. government.

2
00:00:16,500 --> 00:00:19,500
That’s what officially started on Friday
night, and was still going when we

3
00:00:19,500 --> 00:00:20,589
produced this show.

4
00:00:20,589 --> 00:00:22,859
That’s first today on CNN 10.

5
00:00:22,859 --> 00:00:26,660
Congress and the president have to agree on
funding for the U.S. government for all of

6
00:00:26,660 --> 00:00:28,469
its offices to stay open.

7
00:00:28,469 --> 00:00:29,469
They haven’t.

8
00:00:29,469 --> 00:00:30,469
Their latest deadline

9
00:00:30,469 --> 00:00:31,989
to do this was Friday night.

10
00:00:31,989 --> 00:00:36,119
And though the House of Representatives passed
a measure last week to keep the government

11
00:00:36,119 --> 00:00:37,969
funded temporarily, that

12
00:00:37,969 --> 00:00:42,560
measure failed in the Senate, and Democrats
and Republicans spent the weekend blaming

13
00:00:42,560 --> 00:00:44,780
each other for the roadblock.

14
00:00:44,780 --> 00:00:47,929
Republicans control both chambers of Congress
and the White House.

15
00:00:47,929 --> 00:00:52,210
So, Democrats believe voters will blame Republicans
for the shutdown.

16
00:00:52,210 --> 00:00:55,140
But the Republican majority in the Senate
is slim.

17
00:00:55,140 --> 00:01:00,340
They hold 51 seats to the Democrats’ 49,
and Republicans believe Democrats will be

18
00:01:00,340 --> 00:01:01,340
blamed because

19
00:01:01,340 --> 00:01:02,340
they filibuster.

20
00:01:02,340 --> 00:01:07,090
They moved against legislation that would
have kept the government open, and there weren’t

21
00:01:07,090 --> 00:01:09,180
enough votes in the Senate to overcome

22
00:01:09,180 --> 00:01:10,180
the filibuster.

23
00:01:10,180 --> 00:01:12,390
So, why did Democrats filibuster?

24
00:01:12,390 --> 00:01:16,349
Before they approve the budget, they want
an agreement to be reached on what happens

25
00:01:16,349 --> 00:01:19,200
to 700,000 people who came

26
00:01:19,200 --> 00:01:23,030
or were brought to the U.S. illegally as children.

27
00:01:23,030 --> 00:01:27,150
Republicans don’t want to negotiate on that
until enough Democrats vote to reopen the

28
00:01:27,150 --> 00:01:28,150
government

29
00:01:28,150 --> 00:01:29,150
first.

30
00:01:29,150 --> 00:01:32,129
So, yesterday afternoon, both sides were dug
in.

31
00:01:32,129 --> 00:01:37,120
Most Americans are not directly affected by
a government shutdown, but those who are face

32
00:01:37,120 --> 00:01:38,120
some uncertainty.

33
00:01:38,120 --> 00:01:39,120
(BEGIN VIDEOTAPE)

34
00:01:39,120 --> 00:01:41,579
TOM FOREMAN, CNN CORRESPONDENT (voice-over):
Roughly 1.9 million government workers would

35
00:01:41,579 --> 00:01:44,840
be considered essential and stay on the job.

36
00:01:44,840 --> 00:01:50,879
Air traffic controllers, security officers,
food inspectors, prison guards, Social Security

37
00:01:50,879 --> 00:01:52,099
checks would go out.

38
00:01:52,099 --> 00:01:54,150
The post office would be open.

39
00:01:54,150 --> 00:01:55,150
But

40
00:01:55,150 --> 00:01:56,170
at a steep price to many workers.

41
00:01:56,170 --> 00:01:58,599
MICK MULVANEY, DIRECTOR, OFFICE OF MANAGEMENT
AND BUDGET: The military will still go to

42
00:01:58,599 --> 00:01:59,599
work.

43
00:01:59,599 --> 00:02:00,969
They will not get paid, OK?

44
00:02:00,969 --> 00:02:01,969
The border will still

45
00:02:01,969 --> 00:02:02,969
be patrolled.

46
00:02:02,969 --> 00:02:04,129
They will not get paid.

47
00:02:04,129 --> 00:02:07,989
FOREMAN: Meanwhile many services would be
stopped or delayed.

48
00:02:07,989 --> 00:02:12,580
The Centers for Disease Control and Prevention
would back down its flu tracking program

49
00:02:12,580 --> 00:02:16,259
even as the nation faces the worst outbreak
in years.

50
00:02:16,259 --> 00:02:19,158
Some senior nutrition programs would be paused.

51
00:02:19,158 --> 00:02:20,569
Two hundred thousand passport

52
00:02:20,569 --> 00:02:23,969
applications went unprocessed in 1995.

53
00:02:23,969 --> 00:02:27,389
Congress funds much of the scientific research
done in this country.

54
00:02:27,389 --> 00:02:29,039
In 2013, that meant some

55
00:02:29,039 --> 00:02:33,748
experiments went on hold and suffered costly
losses of data.

56
00:02:33,748 --> 00:02:38,509
And in space same year, that same year, for
more than two weeks, NASA reportedly stopped

57
00:02:38,509 --> 00:02:41,818
monitoring potentially dangerous asteroids.

58
00:02:41,818 --> 00:02:42,818
A big one,

59
00:02:42,818 --> 00:02:46,509
by the way, is expected to brush by Earth
on February 4th.

60
00:02:46,509 --> 00:02:47,509
(END VIDEOTAPE)

61
00:02:47,509 --> 00:02:52,150
AZUZ: Activists and protesters, Hollywood
stars and politicians turned out in cities

62
00:02:52,150 --> 00:02:56,158
worldwide over the weekend for what’s called
the Women’s March.

63
00:02:56,158 --> 00:03:01,300
The first one also a massive event, was held
a year ago, on the weekend when U.S. President

64
00:03:01,300 --> 00:03:03,340
Donald Trump was inaugurated.

65
00:03:03,340 --> 00:03:04,539
And many of this year’s

66
00:03:04,539 --> 00:03:09,049
demonstrators, like those in the first women’s
march protested against the election and the

67
00:03:09,049 --> 00:03:11,549
policies of the U.S. leader.

68
00:03:11,549 --> 00:03:16,019
President Trump tweeted that people should
march to celebrate America’s economic success

69
00:03:16,019 --> 00:03:19,509
over the past year, and the lowest female
unemployment in

70
00:03:19,509 --> 00:03:21,120
18 years.

71
00:03:21,120 --> 00:03:23,719
Other issues of the march included sexual
harassment.

72
00:03:23,719 --> 00:03:28,829
Recently, there’s been a wave of acquisitions
against politicians, entertainers and members

73
00:03:28,829 --> 00:03:29,829
of the media.

74
00:03:29,829 --> 00:03:34,430
Religious freedom, immigration, women’s
rights and equality were also addressed by

75
00:03:34,430 --> 00:03:37,370
hundreds of thousand of men, women and children
who

76
00:03:37,370 --> 00:03:38,370
marched in America.

77
00:03:38,370 --> 00:03:39,370
(BEGIN VIDEO CLIP)

78
00:03:39,370 --> 00:03:41,229
AZUZ (voice-over): Ten-second trivia.

79
00:03:41,229 --> 00:03:45,039
Most cars on the road today have what level
of autonomous technology?

80
00:03:45,039 --> 00:03:50,739
None, partial, conditional, or high automation?

81
00:03:50,739 --> 00:03:57,729
The vast majority of today’s cars are still
at level zero, meaning they have no automation

82
00:03:57,729 --> 00:04:00,479
and that the driver is in ultimate control
at all times.

83
00:04:00,479 --> 00:04:01,639
(END VIDEO CLIP)

84
00:04:01,639 --> 00:04:06,930
AZUZ: And that’s even if they have blind
spot monitoring or emergency breaking systems.

85
00:04:06,930 --> 00:04:11,019
The manufacturers are moving toward making
cars with more autonomy.

86
00:04:11,019 --> 00:04:12,979
And one big argument for that safety.

87
00:04:12,979 --> 00:04:15,919
The U.S. government estimates that 94

88
00:04:15,919 --> 00:04:20,858
percent of deadly car crashes are because
of human error and that driverless cars could

89
00:04:20,858 --> 00:04:23,009
significantly reduce that.

90
00:04:23,009 --> 00:04:24,089
But what if they’re

91
00:04:24,089 --> 00:04:25,089
hacked?

92
00:04:25,089 --> 00:04:26,089
(BEGIN VIDEOTAPE)

93
00:04:26,089 --> 00:04:31,459
REPORTER: We all carry computers in our pockets,
and every day machines like thermostats, refrigerator,

94
00:04:31,459 --> 00:04:34,310
cameras, and even our cars are connected

95
00:04:34,310 --> 00:04:37,069
online.

96
00:04:37,069 --> 00:04:42,060
Experts call this constant connection the
Internet of things.

97
00:04:42,060 --> 00:04:46,939
And just like everything else, it’s susceptible
to security breaches.

98
00:04:46,939 --> 00:04:47,939
The two big

99
00:04:47,939 --> 00:04:52,699
questions that I have: could autonomous vehicles
be hacked to hurt us?

100
00:04:52,699 --> 00:04:57,629
And how can we be sure that the personal data
that we produce in these cars are

101
00:04:57,629 --> 00:04:59,279
protected?

102
00:04:59,279 --> 00:05:01,180
The answers are still not perfectly clear.

103
00:05:01,180 --> 00:05:05,850
BRUCE SCHNEIER, CYBER-SECURITY EXPERT: The
Internet of things is going to have enormous

104
00:05:05,850 --> 00:05:09,310
benefits that I think we can’t even begin
to realize -- the

105
00:05:09,310 --> 00:05:14,339
power of computerizing and networking our
environment.

106
00:05:14,339 --> 00:05:15,779
But there are risks also.

107
00:05:15,779 --> 00:05:19,910
Here we are creating an Internet that senses
things and acts.

108
00:05:19,910 --> 00:05:24,000
What we know about computers and software
is that they

109
00:05:24,000 --> 00:05:26,819
have bugs, they have vulnerabilities.

110
00:05:26,819 --> 00:05:29,579
All computer systems can be hacked.

111
00:05:29,579 --> 00:05:35,250
So, you can easily imagine these attacks being
used against cars to cause

112
00:05:35,250 --> 00:05:41,279
the car computer systems to crash, or cars
being used as the attack vector.

113
00:05:41,279 --> 00:05:47,779
So, as we build autonomous systems that affect
the world, in a direct physical manner we

114
00:05:47,779 --> 00:05:50,970
risk bad actors doing it.

115
00:05:50,970 --> 00:05:54,250
We risk glitches and errors,

116
00:05:54,250 --> 00:05:55,959
causing physical harm.

117
00:05:55,959 --> 00:06:01,879
REPORTER: Using cars as weapons is unfortunately
already a tactic used around the world.

118
00:06:01,879 --> 00:06:05,129
The good news is that perhaps far into the
future,

119
00:06:05,129 --> 00:06:09,759
properly functioning autonomous cars won’t
allow humans to hit people.

120
00:06:09,759 --> 00:06:12,850
It could neutralize this tactic of terrorism.

121
00:06:12,850 --> 00:06:13,850
But if the cars can be

122
00:06:13,850 --> 00:06:18,819
controlled remotely or hacked and programmed
to cause harm, it could bring on a whole new

123
00:06:18,819 --> 00:06:21,829
set of issues.

124
00:06:21,829 --> 00:06:26,430
To see what’s being done to make these systems
more secure, I visited a company that actually

125
00:06:26,430 --> 00:06:29,959
started out in the video game industry.

126
00:06:29,959 --> 00:06:31,750
Nvidia now

127
00:06:31,750 --> 00:06:35,360
also makes the graphic processing chips that
go into driverless cars.

128
00:06:35,360 --> 00:06:38,319
DANNY SHAPIRO, SENIOR DIRECTOR OF AUTOMOTIVE
AT NVIDIA: We’ve developed an artificial

129
00:06:38,319 --> 00:06:40,040
intelligent brain for the car.

130
00:06:40,040 --> 00:06:44,500
REPORTER: And how they build those chips will
have major impacts on the safety of future

131
00:06:44,500 --> 00:06:45,579
driverless cars.

132
00:06:45,579 --> 00:06:51,639
SHAPIRO: What we’re building is a computer
first and then a car is built around it.

133
00:06:51,639 --> 00:06:55,699
We’re essentially building a map of the
world in real time

134
00:06:55,699 --> 00:06:57,790
based on what we sense.

135
00:06:57,790 --> 00:07:04,889
We had cameras, ultrasonic sensors, radars,
Lidar, which is a laser scanner, and each

136
00:07:04,889 --> 00:07:06,750
of those sensors are generating a

137
00:07:06,750 --> 00:07:08,410
massive amount of data.

138
00:07:08,410 --> 00:07:12,250
REPORTER: Data collection is crucial for allowing
these cars to function.

139
00:07:12,250 --> 00:07:15,670
But like security, it also raises questions
about how the information

140
00:07:15,670 --> 00:07:18,379
gathered from our personal lives will be used.

141
00:07:18,379 --> 00:07:22,689
The new technology has the attention of privacy
advocates like Lauren Smith at the Future

142
00:07:22,689 --> 00:07:23,689
of Privacy

143
00:07:23,689 --> 00:07:28,589
Forum in Washington, D.C., a group that explores
issues with all sorts of home gadgets, like

144
00:07:28,589 --> 00:07:32,769
Amazon Echo’s Alexa system, drones, even
smart dolls.

145
00:07:32,769 --> 00:07:35,300
LAUREN SMITH, FUTURE OF PRIVACY FORUM: Alexa,
are you spying on me?

146
00:07:35,300 --> 00:07:40,660
AMAZON ECHO’S ALEXA SYSTEM: I only send
audio back to Amazon when I hear you say wake

147
00:07:40,660 --> 00:07:41,660
word.

148
00:07:41,660 --> 00:07:43,089
REPORTER: And now, autonomous cars.

149
00:07:43,089 --> 00:07:46,810
SMITH: It’s important that people start
to think about their cars in the same way

150
00:07:46,810 --> 00:07:49,639
that they think about their computer or smartphone.

151
00:07:49,639 --> 00:07:50,639
So, if you

152
00:07:50,639 --> 00:07:55,420
use a technology like this that relies on
connectivity, that relies on data inputs and

153
00:07:55,420 --> 00:08:00,860
outputs, you are creating sort of an information
trail.

154
00:08:00,860 --> 00:08:05,079
SCHNEIER: Data has good and bad uses.

155
00:08:05,079 --> 00:08:10,110
There are some very powerful reasons to collect
data about us and our society and put it together

156
00:08:10,110 --> 00:08:11,110
so we

157
00:08:11,110 --> 00:08:13,579
can do research, we can data-deliver services.

158
00:08:13,579 --> 00:08:15,970
Smart government is the wave of the future.

159
00:08:15,970 --> 00:08:20,430
But the same data can be used for surveillance,
for

160
00:08:20,430 --> 00:08:21,430
control.

161
00:08:21,430 --> 00:08:26,740
I don’t really think any government is prepared
for the Internet of things and what it’s

162
00:08:26,740 --> 00:08:29,370
going to do.

163
00:08:29,370 --> 00:08:33,759
These are computers that affect the world
in direct physical manner.

164
00:08:33,759 --> 00:08:37,158
And there are risks to life and property.

165
00:08:37,158 --> 00:08:43,208
Largely, Western governments have taken a
very hands-off view to regulation of Internet.

166
00:08:43,208 --> 00:08:45,269
The United States is special.

167
00:08:45,269 --> 00:08:46,809
And that worked great when it

168
00:08:46,809 --> 00:08:53,629
didn’t matter, when it was data, when it
was a spreadsheet, when it was conversation.

169
00:08:53,629 --> 00:08:56,929
But when it’s a car and it’s a medical
device, when it’s an

170
00:08:56,929 --> 00:09:03,549
appliance, when it can actually do physical
harm, that changes everything.

171
00:09:03,549 --> 00:09:05,879
(END VIDEOTAPE)

172
00:09:05,879 --> 00:09:08,208
AZUZ: OK.

173
00:09:08,208 --> 00:09:14,299
So, let’s pretend a freezer malfunctions
and continues making ice long after the tray

174
00:09:14,299 --> 00:09:15,528
is full.

175
00:09:15,528 --> 00:09:17,139
That might look a bit like what happened

176
00:09:17,139 --> 00:09:21,970
recently in Ohio, except that in this case,
the freezer was the Arctic and the tray was

177
00:09:21,970 --> 00:09:23,620
Lake Erie.

178
00:09:23,620 --> 00:09:29,698
Ice shoves or ice tsunamis formed when winds
blow ice across the lake and into its shores

179
00:09:29,698 --> 00:09:32,899
where it files and forms mountains of ice.

180
00:09:32,899 --> 00:09:33,899
Some hills here

181
00:09:33,899 --> 00:09:36,600
grew to be more than 30 feet high.

182
00:09:36,600 --> 00:09:40,458
If they’re not fans of "Frozen", the locals
better hope it stops or Elsa.

183
00:09:40,458 --> 00:09:44,860
Sure, some fans may find it Arendelightful
but it’s hard to conceal don’t

184
00:09:44,860 --> 00:09:49,759
feel when a lake shore crystallizes like an
icy blast, potentially causing an Olaf of

185
00:09:49,759 --> 00:09:50,759
problems.

186
00:09:50,759 --> 00:09:52,669
Unless, of course, the cold doesn’t bother
you

187
00:09:52,669 --> 00:09:53,669
anyway.

188
00:09:53,669 --> 00:09:56,774
I’m Carl Azuz for CNN 10.


